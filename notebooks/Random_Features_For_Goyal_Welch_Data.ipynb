{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ee5614e1",
      "metadata": {
        "id": "ee5614e1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "a158cdc0",
      "metadata": {
        "id": "a158cdc0"
      },
      "outputs": [],
      "source": [
        "def scatter_plot(x_: np.ndarray,\n",
        "                 y_: np.ndarray,\n",
        "                 name_x: str,\n",
        "                 name_y: str,\n",
        "                 ax=None):\n",
        "    \"\"\"\n",
        "    scatter plot\n",
        "    \"\"\"\n",
        "    data = pd.DataFrame(np.concatenate([x_, y_], axis=1),\n",
        "                    columns=[name_x, name_y])\n",
        "    if ax is None:\n",
        "        sns.jointplot(data=data, x=name_x, y=name_y, kind=\"reg\")\n",
        "    else:\n",
        "        sns.jointplot(data=data, x=name_x, y=name_y, kind=\"reg\", ax=ax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "fed9a583",
      "metadata": {
        "id": "fed9a583"
      },
      "outputs": [],
      "source": [
        "def performance_metrics_of_regression(labels: np.ndarray,\n",
        "                                      predictions: np.ndarray) -> tuple:\n",
        "    \"\"\"\n",
        "    Compute standard performance metrics for regression: mse and Rsquared\n",
        "    \"\"\"\n",
        "    mse = ((predictions - labels) ** 2).mean()\n",
        "    r2 = 1 - mse / (labels ** 2).mean()\n",
        "    print(f'r2 = {\"%.2f\" % r2}, mse = {\"%.2f\" % mse}')\n",
        "\n",
        "    return mse, r2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zslhFr8SUh8L",
      "metadata": {
        "id": "zslhFr8SUh8L"
      },
      "source": [
        "#We now experiment with random features ([Random Features for Large-Scale Kernel Machines](https://people.eecs.berkeley.edu/~brecht/papers/07.rah.rec.nips.pdf)) applied to the classic dataset from [A Comprehensive Look at the Empirical Performance of Equity Premium Prediction](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=517667) and implemented in [The Virtue of Complexity in Return Prediction](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3984925). We will also load the FRED-MD dataset from [FRED-MD](https://research.stlouisfed.org/wp/more/2015-012)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "aguPsCkQ0LFx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aguPsCkQ0LFx",
        "outputId": "ba29b82e-d7cb-4794-a1b0-d255c4213d12"
      },
      "outputs": [],
      "source": [
        "# AND NOW WE START WORKING WITH REAL DATA\n",
        "# import os\n",
        "# from google.colab import drive\n",
        "# import pandas as pd\n",
        "# drive.mount('/content/gdrive')\n",
        "# folder = '/content/gdrive/My Drive/macro_data'\n",
        "\n",
        "goyal_welch_data = pd.read_csv('../macro_data/GoyalWelchPredictorData2022Monthly.csv', index_col=0)\n",
        "goyal_welch_data.index = pd.to_datetime(goyal_welch_data.index, format='%Y%m')\n",
        "\n",
        "#fred_data = pd.read_csv(os.path.join(folder,'FRED_MD.csv'), index_col=0).iloc[1:, :]\n",
        "#fred_data.index = pd.to_datetime(fred_data.index)\n",
        "\n",
        "for column in goyal_welch_data.columns:\n",
        "    goyal_welch_data[column] = [float(str(x).replace(',', '')) for x in goyal_welch_data[column]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tXMTDbnlLjUn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "tXMTDbnlLjUn",
        "outputId": "8c90f30a-abed-4867-d5cf-7a6313c6b4de"
      },
      "outputs": [],
      "source": [
        "goyal_welch_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86ff011c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "86ff011c",
        "outputId": "ca5d84a9-aa54-4f20-f648-fcea1ca29808"
      },
      "outputs": [],
      "source": [
        "goyal_welch_data['Index'].plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca13c4ec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "ca13c4ec",
        "outputId": "55f956ab-997a-446d-cdf8-28cf67d4be25"
      },
      "outputs": [],
      "source": [
        "np.log(goyal_welch_data['Index']).plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0916d1e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0916d1e",
        "outputId": "fe883c68-1867-4652-ed00-ee076c3466f3"
      },
      "outputs": [],
      "source": [
        "goyal_welch_data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8f58ebd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "a8f58ebd",
        "outputId": "26ef8589-68f4-43d0-fc26-2190d2958fc8"
      },
      "outputs": [],
      "source": [
        "(12 * goyal_welch_data.Rfree).plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e2b1084",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "id": "1e2b1084",
        "outputId": "6a6ea934-5f30-478e-b413-116e49f9c0f4"
      },
      "outputs": [],
      "source": [
        "goyal_welch_data.tail(20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "68c8d70e",
      "metadata": {
        "id": "68c8d70e"
      },
      "outputs": [],
      "source": [
        "goyal_welch_data['returns'] = ((goyal_welch_data.Index)/ goyal_welch_data.Index.shift(1) - 1).fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "916a87a3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "916a87a3",
        "outputId": "fe10fa5e-d790-4349-f466-35941c36088c"
      },
      "outputs": [],
      "source": [
        "goyal_welch_data['returns'].describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1df72e55",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "1df72e55",
        "outputId": "f080b640-76c3-4264-b1b0-30380bff3132"
      },
      "outputs": [],
      "source": [
        "goyal_welch_data.Rfree.describe()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "n-fSTGBy8yTX",
      "metadata": {
        "id": "n-fSTGBy8yTX"
      },
      "source": [
        "#Excess returns are defined as $R_{t+1}-r_{f,t}$ (in excess of the risk-free rate). Then, we know that, with portfolio weight $\\pi_t,$ the wealth evolves as\n",
        "$$\n",
        "W_{t+1}\\ =\\ W_t(r_{f,t} + \\pi_t (R_{t+1}-r_{f,t}))\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccffb956",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "ccffb956",
        "outputId": "2ab414c3-6c3d-4dd5-9ab7-426e20d42a61"
      },
      "outputs": [],
      "source": [
        "goyal_welch_data['excess_returns'] = goyal_welch_data.returns - goyal_welch_data.Rfree\n",
        "leverage = 20.\n",
        "strategy_returns = 1 + goyal_welch_data.Rfree + leverage * goyal_welch_data.excess_returns\n",
        "plt.plot(np.cumprod(strategy_returns))\n",
        "plt.title(f'leverage = {leverage}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b499cfe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b499cfe",
        "outputId": "a6a2229c-5f9a-4331-993b-00d40bf615bd"
      },
      "outputs": [],
      "source": [
        "goyal_welch_data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05ff401b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "05ff401b",
        "outputId": "2627cb6b-221c-4c8e-c674-395c58d121a1"
      },
      "outputs": [],
      "source": [
        "(12 * goyal_welch_data.infl).plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a14ed8b9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "a14ed8b9",
        "outputId": "4407a18a-2af6-4057-9903-723637cc5846"
      },
      "outputs": [],
      "source": [
        "goyal_welch_data.infl.describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "019dfbe9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "id": "019dfbe9",
        "outputId": "81e4a187-578d-4cd3-e471-0f3a13e370e4"
      },
      "outputs": [],
      "source": [
        "goyal_welch_data.tail(20)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddaf9ec5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 665
        },
        "id": "ddaf9ec5",
        "outputId": "8c7c45d4-3f68-4361-9139-967c2de74fbc"
      },
      "outputs": [],
      "source": [
        "goyal_welch_data.corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a029e91c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "a029e91c",
        "outputId": "2f1db3f1-68c9-4e73-c6c9-496ed61ad2a0"
      },
      "outputs": [],
      "source": [
        "goyal_welch_data.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e00ea4e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "5e00ea4e",
        "outputId": "86905168-56e5-471e-fc10-bb02c8ce6967"
      },
      "outputs": [],
      "source": [
        "goyal_welch_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "4a6f2dbf",
      "metadata": {
        "id": "4a6f2dbf"
      },
      "outputs": [],
      "source": [
        "cleaned_data = goyal_welch_data.loc['1975':].drop(columns=['csp']).fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed8c1142",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "ed8c1142",
        "outputId": "6c191c90-9077-4e2f-e604-3ff83c109da9"
      },
      "outputs": [],
      "source": [
        "cleaned_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RbZMDxbY1E3W",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbZMDxbY1E3W",
        "outputId": "7e456ccc-449f-4e80-e7b4-fe7f50b2f13d"
      },
      "outputs": [],
      "source": [
        "cleaned_data[['Index', 'D12', 'E12']] = (cleaned_data[['Index', 'D12', 'E12']] / cleaned_data[['Index', 'D12', 'E12']].shift(1)).fillna(0)\n",
        "print(cleaned_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QbmnE1S5NaVb",
      "metadata": {
        "id": "QbmnE1S5NaVb"
      },
      "source": [
        "# **Do not forget to shift the signals !!!!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6e22a55",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6e22a55",
        "outputId": "d880e01f-f498-40ae-acda-c52dda256253"
      },
      "outputs": [],
      "source": [
        "signal_columns = ['Index', 'D12', 'E12', 'b/m', 'tbl', 'AAA', 'BAA', 'lty', 'ntis',\n",
        "        'Rfree', 'infl', 'ltr', 'corpr', 'svar']\n",
        "\n",
        "data_for_signals = cleaned_data[signal_columns].shift(1).fillna(0) # shifting of signals happens here !\n",
        "labels = cleaned_data.excess_returns.values.reshape(-1, 1)\n",
        "data_for_signals['infl'] = data_for_signals['infl'].shift(1).fillna(0) # this is because inflation is actually published later\n",
        "signals = data_for_signals.values\n",
        "data_for_signals.shape, data_for_signals.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "X-qoxxsQNntA",
      "metadata": {
        "id": "X-qoxxsQNntA"
      },
      "source": [
        "# Now comes (as usual) our favorite regression function\n",
        "# Recall that we would like to compute $(zI+SS'/T)^{-1}$ for many values of $z.$ Doing this is slow because matrix inversion is slow. Instead, we will only pay the cost of matrix manipulations just once. We do this by performing the eigenvalue decomposition\n",
        "$$\n",
        "SS'/T\\ =\\ U DU'\n",
        "$$\n",
        "#and then use the mathematical formula\n",
        "$$\n",
        "(zI+SS'/T)^{-1}\\ =\\ U (zI+D)^{-1}U'\\,.\n",
        "$$\n",
        "#The **estimated** regression coefficients for $y=S\\beta+\\epsilon$ are\n",
        "$$\n",
        "\\hat\\beta(z)\\ =\\ (zI+S'S/T)^{-1}S'y/T\\ =\\ S'(zI+SS'/T)^{-1}y/T\n",
        "$$\n",
        "#and we can thus rewrite it as\n",
        "$$\n",
        "S'(zI+SS'/T)^{-1}y/T\\ =\\ S'U (zI+D)^{-1}U' y/T\\,.\n",
        "$$\n",
        "#So we proceed as follows. First, we compute\n",
        "$$\n",
        "\\mu\\ =\\ U' y/T\n",
        "$$\n",
        "#Now, let $\\delta$ be the vector of diagoal elements of $D$. Then,\n",
        "$$\n",
        "[(z_1I+D)^{-1}\\mu, \\cdots, (z_KI+D)^{-1}\\mu]\\ =\\ [(z_1+\\delta)^{-1}, \\cdots, (z_K+\\delta)^{-1}]*\\mu\n",
        "$$\n",
        "#Here, $[(z_1+\\delta)^{-1}, \\cdots, (z_K+\\delta)^{-1}]$ is the matrix with $K$ columns and $T$ rows, because $\\mu$ and $\\delta$ are $T$-dimensional.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "AYXGl9KGp12c",
      "metadata": {
        "id": "AYXGl9KGp12c"
      },
      "outputs": [],
      "source": [
        "def ridge_regr(signals: np.ndarray,\n",
        "                labels: np.ndarray,\n",
        "                future_signals: np.ndarray,\n",
        "                shrinkage_list: np.ndarray):\n",
        "    \"\"\"\n",
        "    Regression is\n",
        "    beta = (zI + S'S/t)^{-1}S'y/t = S' (zI+SS'/t)^{-1}y/t\n",
        "    Inverting matrices is costly, so we use eigenvalue decomposition:\n",
        "    (zI+A)^{-1} = U (zI+D)^{-1} U' where UDU' = A is eigenvalue decomposition,\n",
        "    and we use the fact that D @ B = (diag(D) * B) for diagonal D, which saves a lot of compute cost\n",
        "    :param signals: S\n",
        "    :param labels: y\n",
        "    :param future_signals: out of sample y\n",
        "    :param shrinkage_list: list of ridge parameters\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    t_ = signals.shape[0]\n",
        "    p_ = signals.shape[1]\n",
        "    if p_ < t_:\n",
        "        # this is standard regression\n",
        "        eigenvalues, eigenvectors = np.linalg.eigh(signals.T @ signals / t_)\n",
        "        means = signals.T @ labels.reshape(-1, 1) / t_\n",
        "        multiplied = eigenvectors.T @ means\n",
        "        intermed = np.concatenate([(1 / (eigenvalues.reshape(-1, 1) + z)) * multiplied for z in shrinkage_list],\n",
        "                                  axis=1)\n",
        "        betas = eigenvectors @ intermed\n",
        "    else:\n",
        "        # this is the weird over-parametrized regime\n",
        "        eigenvalues, eigenvectors = np.linalg.eigh(signals @ signals.T / t_)\n",
        "        means = labels.reshape(-1, 1) / t_\n",
        "        multiplied = eigenvectors.T @ means # this is \\mu\n",
        "\n",
        "        # now we build [(z_1+\\delta)^{-1}, \\cdots, (z_K+\\delta)^{-1}] * \\mu\n",
        "        intermed = np.concatenate([(1 / (eigenvalues.reshape(-1, 1) + z)) * multiplied for z in shrinkage_list],\n",
        "                                  axis=1)\n",
        "\n",
        "        tmp = eigenvectors.T @ signals # U.T @ S\n",
        "        betas = tmp.T @ intermed # (S.T @ U) @ [(z_1+\\delta)^{-1}, \\cdots, (z_K+\\delta)^{-1}] * \\mu\n",
        "    predictions = future_signals @ betas\n",
        "    return betas, predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FmqwAaICOERS",
      "metadata": {
        "id": "FmqwAaICOERS"
      },
      "source": [
        "# Sometimes, data normalization can be important. We introduce a function to do it here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "kEk-26tRN6ak",
      "metadata": {
        "id": "kEk-26tRN6ak"
      },
      "outputs": [],
      "source": [
        "def normalize(data: np.ndarray,\n",
        "              ready_normalization: dict = None,\n",
        "              use_std: bool = False)->tuple:\n",
        "  \"\"\"\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  if ready_normalization is None:\n",
        "      data_std = data.std(0)\n",
        "      data_mean = data.mean(0)\n",
        "      if use_std:\n",
        "        data = (data - data_mean) / data_std # this is z-scoring of the data\n",
        "      else:\n",
        "        data_max = np.max(data, axis=0)\n",
        "        data_min = np.min(data, axis=0)\n",
        "  else:\n",
        "      data_std = ready_normalization['std']\n",
        "      data_mean = ready_normalization['mean']\n",
        "      if use_std:\n",
        "        data = (data - data_mean) / data_std # this is z-scoring of the data\n",
        "      else:\n",
        "        data_max = ready_normalization['max']\n",
        "        data_min = ready_normalization['min']\n",
        "  if not use_std:\n",
        "    data = data - data_min\n",
        "    data = data/(data_max - data_min)\n",
        "    data = data - 0.5\n",
        "  normalization = {'std': data_std,\n",
        "                   'mean': data_mean,\n",
        "                    'max': data_max,\n",
        "                    'min': data_min}\n",
        "  return data, normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8qZgGgdgqzfi",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qZgGgdgqzfi",
        "outputId": "336b7551-f505-4b0a-e8cb-e671f315a143"
      },
      "outputs": [],
      "source": [
        "signals.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58781b2b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58781b2b",
        "outputId": "07e9ee7d-ea6d-405a-bfa4-de9d2538fa32"
      },
      "outputs": [],
      "source": [
        "normalize_raw_data = True\n",
        "cheat_and_use_future_data = False  # set to True if you want to have\n",
        "#our fun experiment to show how even know a bit about the future can drastically imprpve performance\n",
        "\n",
        "shrinkage_list = [0.00000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
        "\n",
        "split = int(signals.shape[0] / 2)\n",
        "train_labels = labels[:split]\n",
        "test_labels = labels[split:]\n",
        "\n",
        "if normalize_raw_data:\n",
        "    signals[:split, :], normalization_based_on_train = normalize(signals[:split], use_std=False)\n",
        "    # this is our fun experiment to show how even know a bit about the future can drastically imprpve performance\n",
        "    if cheat_and_use_future_data:\n",
        "      signals[split:, :] = normalize(signals[split:, :])[0]\n",
        "    else:\n",
        "      signals[split:, :] = normalize(signals[split:, :],\n",
        "                                     ready_normalization=normalization_based_on_train)[0]\n",
        "\n",
        "beta_estimate_using_train_sample, oos_predictions = ridge_regr(signals=signals[:split, :],\n",
        "                                                                labels=train_labels,\n",
        "                                                                future_signals=signals[split:, :],\n",
        "                                                                shrinkage_list=shrinkage_list)\n",
        "\n",
        "oos_predictions = pd.DataFrame(oos_predictions, index=cleaned_data.index[split:], columns = shrinkage_list)\n",
        "print(oos_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QJMQfpw3Z9Hc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "QJMQfpw3Z9Hc",
        "outputId": "c2e95a1b-0d3b-47a0-f6ee-6805f0b916fc"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(beta_estimate_using_train_sample, columns=shrinkage_list, index=data_for_signals.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sInzJApng1c_",
      "metadata": {
        "id": "sInzJApng1c_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "f8xQaswAgqCL",
      "metadata": {
        "id": "f8xQaswAgqCL"
      },
      "source": [
        "# Now we compute managed returns $\\pi_t(z) \\cdot R_{t+1}.$ Because we are predicting the market, we are \"timing the market\" and hence we will also call them \"market timing returns\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2869d8df",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2869d8df",
        "outputId": "5451e14d-3538-4605-b0a3-c6451c416a88"
      },
      "outputs": [],
      "source": [
        "market_timing_returns = oos_predictions * test_labels.reshape(-1, 1)\n",
        "print(market_timing_returns) # we have one timing return for each value of z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "7SZ70_ssb0Jk",
      "metadata": {
        "id": "7SZ70_ssb0Jk"
      },
      "outputs": [],
      "source": [
        "def sharpe_ratio(x):\n",
        "  # We are computing the ANNUALIZED SHARPE RATIO, hence we need to multiply by sqrt(12)\n",
        "  return np.round(np.sqrt(12) * x.mean(0) / x.std(0), 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "cf501ab7",
      "metadata": {
        "id": "cf501ab7"
      },
      "outputs": [],
      "source": [
        "cleaned_data = pd.concat([cleaned_data, market_timing_returns], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "b3037a01",
      "metadata": {
        "id": "b3037a01"
      },
      "outputs": [],
      "source": [
        "tmp = cleaned_data[['excess_returns'] + shrinkage_list].iloc[split:]\n",
        "tmp = tmp / tmp.std()\n",
        "sr = sharpe_ratio(tmp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af7aba35",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "af7aba35",
        "outputId": "142ae83e-dd11-46bf-986a-f4d437a613c9"
      },
      "outputs": [],
      "source": [
        "tmp.cumsum().plot()\n",
        "plt.title(f'SR={sr.values.flatten()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1CqwOFuPwJcL",
      "metadata": {
        "id": "1CqwOFuPwJcL"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "_GEuFCn1wJsJ",
      "metadata": {
        "id": "_GEuFCn1wJsJ"
      },
      "source": [
        "# We now investigate the statistical significance of our strategy performance relative to that of the two benchmarks: the market and the simple, linear strategy. To this end, we run the following regression\n",
        "$$\n",
        "R_{t+1}^{simple\\ linear}\\ =\\ \\alpha\\ +\\ \\beta R_{t+1}^{market}\n",
        "$$\n",
        "#We would like to see a large positive t-statistic for the $\\alpha$ coefficient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "iJJIJP2STAYB",
      "metadata": {
        "id": "iJJIJP2STAYB"
      },
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "def regression_with_tstats(predicted_variable, explanatory_variables):\n",
        "    x_ = explanatory_variables\n",
        "    x_ = sm.add_constant(x_)\n",
        "    y_ = predicted_variable\n",
        "    # Newey-West standard errors with maxlags\n",
        "    z_ = x_.copy().astype(float)\n",
        "    result = sm.OLS(y_.values, z_.values).fit(cov_type='HAC', cov_kwds={'maxlags': 10})\n",
        "    try:\n",
        "        tstat = np.round(result.summary2().tables[1]['z'], 1)  # alpha t-stat (because for 'const')\n",
        "        tstat.index = list(z_.columns)\n",
        "    except:\n",
        "        print(f'something is wrong for t-stats')\n",
        "    return tstat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XnOUsrzxTEQP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnOUsrzxTEQP",
        "outputId": "505d0de9-7e31-4093-e97e-bd2f3676449b"
      },
      "outputs": [],
      "source": [
        "tstat = regression_with_tstats(predicted_variable=tmp[1.], explanatory_variables=tmp['excess_returns'])\n",
        "print(tstat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pBXS3fHtTjwo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "pBXS3fHtTjwo",
        "outputId": "c224b57c-5dfa-4c69-dcdd-19575312fb24"
      },
      "outputs": [],
      "source": [
        "tmp[1.]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0rn1yFXMVZm1",
      "metadata": {
        "id": "0rn1yFXMVZm1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "HPtaBt-Wa8Wn",
      "metadata": {
        "id": "HPtaBt-Wa8Wn"
      },
      "source": [
        "# **NOW COME THE RANDOM FEATURES**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2gfYkLFtQZ8X",
      "metadata": {
        "id": "2gfYkLFtQZ8X"
      },
      "source": [
        "#The scale of random weights entering random features is very important.\n",
        "\n",
        "#There are two equivalent ways to control the scale of your linear random features. One is to generate $\\omega\\sim N(0,1)$ and then use $\\gamma\\cdot \\omega$ for some $\\gamma\\in \\mathbb R$. This $\\gamma$ controls the scale of the your features. Another way is to directly sample $\\omega\\sim N(0, \\gamma^2).$ Mathematically, this is based on the important observation that if $\\omega\\sim N(0,1)$, then $\\gamma\\omega\\sim N(0, \\gamma^2).$\n",
        "\n",
        "#The intuition is based on the Taylor approximation.  We have $h(\\gamma \\cdot \\omega'x) \\approx h(0)+h'(0) \\gamma \\omega' x$ when $\\gamma$ is small enough. That is, our non-linear random features become approximately linear. **Thus, the bigger $\\gamma$ is, the more non-linear the features are.**\n",
        "\n",
        "#**This scale is also important for neural networks, and is pinned down through initialization!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "f30987f4",
      "metadata": {
        "id": "f30987f4"
      },
      "outputs": [],
      "source": [
        "P = 50000\n",
        "d = 14\n",
        "scale = 1.\n",
        "omega = scale * np.sqrt(2) * np.random.randn(d, P) / np.sqrt(d)\n",
        "ins_sin = np.sqrt(2) * np.sin(signals @ omega) # this is n times P\n",
        "ins_cos = np.sqrt(2) * np.cos(signals @ omega) # this is also n times P\n",
        "random_features = np.append(ins_sin, ins_cos, axis=1) # this is n times (2P)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d4e4b99",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d4e4b99",
        "outputId": "f77dc676-4696-4009-ed89-88c5d641f671"
      },
      "outputs": [],
      "source": [
        "random_features.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1196f2de",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1196f2de",
        "outputId": "9dc0398a-abe0-49d1-efdf-cf6f2844b657"
      },
      "outputs": [],
      "source": [
        "split = int(signals.shape[0] / 2)\n",
        "\n",
        "labels = cleaned_data.excess_returns.values.reshape(-1, 1)\n",
        "\n",
        "train_labels = labels[:split]\n",
        "test_labels = labels[split:]\n",
        "\n",
        "beta_estimate_using_train_sample, oos_predictions = ridge_regr(signals=random_features[:split, :],\n",
        "                                                                labels=train_labels,\n",
        "                                                                future_signals=random_features[split:, :],\n",
        "                                                                shrinkage_list=shrinkage_list)\n",
        "\n",
        "oos_predictions = pd.DataFrame(oos_predictions, index=cleaned_data.index[split:], columns = shrinkage_list)\n",
        "print(oos_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TJg5MQhLD1LO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 993
        },
        "id": "TJg5MQhLD1LO",
        "outputId": "c7b3de66-c5b9-4b7e-b54c-7d80a987fd27"
      },
      "outputs": [],
      "source": [
        "market_timing_returns_complex = oos_predictions * test_labels\n",
        "market_timing_returns_complex.columns = [f'{x}_complex' for x in market_timing_returns_complex.columns]\n",
        "\n",
        "cleaned_data = pd.concat([cleaned_data, market_timing_returns_complex], axis=1)\n",
        "\n",
        "# 'excess_returns' are just market returns; it is important we keep them\n",
        "# shrinkage_list: these are the columns corresponding to the simple linear model with just 13 predictors\n",
        "tmp = cleaned_data[['excess_returns'] + shrinkage_list + list(market_timing_returns_complex.columns)].iloc[split:, :]\n",
        "tmp = tmp / tmp.std()\n",
        "tmp['mean'] = tmp.mean(1)\n",
        "sr = sharpe_ratio(tmp)\n",
        "tmp.cumsum().plot()\n",
        "plt.title(f'sr={sr}')\n",
        "plt.savefig(os.path.join(folder, 'performance_pl9ot.jpeg'))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e6c2075",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4e6c2075",
        "outputId": "a3726fcc-6b81-48e5-d386-f8cd82ff38e8"
      },
      "outputs": [],
      "source": [
        "cleaned_data.corr()[0.001]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "wshc9jbre28V",
      "metadata": {
        "id": "wshc9jbre28V"
      },
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "def regression_with_tstats(predicted_variable, explanatory_variables):\n",
        "    x_ = explanatory_variables\n",
        "    x_ = sm.add_constant(x_)\n",
        "    y_ = predicted_variable\n",
        "    # Newey-West standard errors with maxlags\n",
        "    z_ = x_.copy().astype(float)\n",
        "    result = sm.OLS(y_.values, z_.values).fit(cov_type='HAC', cov_kwds={'maxlags': 10})\n",
        "    try:\n",
        "        tstat = np.round(result.summary2().tables[1]['z'], 1)  # alpha t-stat (because for 'const')\n",
        "        tstat.index = list(z_.columns)\n",
        "    except:\n",
        "        print(f'something is wrong for t-stats')\n",
        "    return tstat"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "la-wTy0XzvmN",
      "metadata": {
        "id": "la-wTy0XzvmN"
      },
      "source": [
        "# We now investigate the statistical significance of our strategy performance relative to that of the two benchmarks: the market and the simple, linear strategy. To this end, we run the following regression\n",
        "$$\n",
        "R_{t+1}^{complex}\\ =\\ \\alpha\\ +\\ \\beta_1 R_{t+1}^{market}\\ +\\ \\beta_2 R_{t+1}^{simple\\ linear}\n",
        "$$\n",
        "#We would like to see a large positive t-statistic for the $\\alpha$ coefficient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96VC3pfyzFsQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96VC3pfyzFsQ",
        "outputId": "422e8943-12b0-48f3-f40e-6f135296f72e"
      },
      "outputs": [],
      "source": [
        "tstats = regression_with_tstats(predicted_variable=tmp['0.001_complex'], explanatory_variables=tmp[['excess_returns', 0.001]])\n",
        "print(tstats)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "468b5ac4",
      "metadata": {},
      "source": [
        "# SPY ticker "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e50d83d",
      "metadata": {},
      "outputs": [],
      "source": [
        "%run ./Macro_Assets.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f755669",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Store a copy of the original data before modifying it\n",
        "original_spy_data_full = spy_data_full.copy()\n",
        "spy_data_full"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca214732",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate monthly returns\n",
        "spy_data_full['returns'] = spy_data_full['Close'].pct_change().fillna(0)\n",
        "\n",
        "# Merge with the risk-free rate \n",
        "spy_data_full = spy_data_full.join(cleaned_data[['Rfree']], how='left')\n",
        "\n",
        "# Excess returns\n",
        "spy_data_full['excess_returns'] = spy_data_full['returns'] - spy_data_full['Rfree']\n",
        "\n",
        "spy_data_full.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdd825b4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Signal columns \n",
        "SPY_df_signals = original_spy_data_full.join(data_for_signals[signal_columns], how='left')\n",
        "\n",
        "SPY_df_signals\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1985ef08",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
